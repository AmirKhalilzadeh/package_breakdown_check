{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook aimes to automate the process of extracting and analyzing import statements from multiple Jupyter Notebooks within a GitHub repository. The main idea is to collect all the import statements from the code cells of these notebooks to check for dependency breakdowns and version conflicts upon an update in the virtual environment.\n",
    "\n",
    "### Outline\n",
    "\n",
    "- **GitHub authentication and repository access**\n",
    "\n",
    "- **Extracting import statements**\n",
    "\n",
    "- **Processing import statements and validation**:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from github import Github\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Authenticaton\n",
    "\n",
    "Accessed the specified repository and retrieved all notebook files within it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the GitHub token from environment variable\n",
    "token = os.getenv(\"GITHUB_TOKEN_prj_pkg\")\n",
    "\n",
    "# authenticate to github\n",
    "g = Github(token)\n",
    "\n",
    "# get the authenticated user\n",
    "user = g.get_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: AmirKhalilzadeh\n",
      "Found repository: epfl-exts/adsml-ibex\n"
     ]
    }
   ],
   "source": [
    "# print the authenticated user's login\n",
    "print(f\"Authenticated as: {user.login}\")\n",
    "\n",
    "# define the organization and repository name\n",
    "org_name = \"epfl-exts\"  # Replace with the actual organization name\n",
    "repo_name = \"adsml-ibex\"  # Replace with the actual repository name\n",
    "\n",
    "# check if you find the repository\n",
    "repo = g.get_repo(f\"{org_name}/{repo_name}\")\n",
    "print(f\"Found repository: {repo.full_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting import statements\n",
    "\n",
    "Define functions to recursively get all notebook files and extract import statements from the code cells. Then collect all import statements from the notebooks and stored them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursively get all notebook files in a repository\n",
    "def get_notebook_files(repo, path=\"\"):\n",
    "    contents = repo.get_contents(path)\n",
    "    notebooks = []\n",
    "    for content_file in contents:\n",
    "        if content_file.type == \"dir\":\n",
    "            notebooks.extend(get_notebook_files(repo, content_file.path))\n",
    "        elif content_file.name == \"notebook.ipynb\":\n",
    "            notebooks.append(content_file.path)\n",
    "    return notebooks\n",
    "\n",
    "\n",
    "# extract import statements from a notebook\n",
    "def extract_import_statements(notebook_content):\n",
    "    import_statements = []\n",
    "    for cell in notebook_content[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            for line in cell[\"source\"]:\n",
    "                if line.startswith(\"import\") or line.startswith(\"from\"):\n",
    "                    import_statements.append(line.strip())\n",
    "    return import_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'notebook.ipynb'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all notebook files in the repository\n",
    "notebook_files = get_notebook_files(repo)\n",
    "\n",
    "# Extract the base names of the notebook files\n",
    "notebook_names = [os.path.basename(file) for file in notebook_files]\n",
    "\n",
    "# Print the unique names\n",
    "display(set(notebook_names))\n",
    "len(notebook_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from IPython.display import display',\n",
       " 'from PIL import Image',\n",
       " 'from bs4 import BeautifulSoup',\n",
       " 'from collections import Counter',\n",
       " 'from components import QuizzComponent',\n",
       " 'from gensim.models import Phrases',\n",
       " 'from itertools import product',\n",
       " 'from matplotlib import pyplot as plt',\n",
       " 'from matplotlib.patches import Ellipse',\n",
       " 'from mpl_toolkits.mplot3d import Axes3D',\n",
       " 'from nltk.corpus import stopwords',\n",
       " 'from nltk.stem.porter import PorterStemmer',\n",
       " 'from nltk.tokenize import TreebankWordTokenizer',\n",
       " 'from nltk.tokenize import sent_tokenize',\n",
       " 'from pandas import json_normalize',\n",
       " 'from pandas.plotting import autocorrelation_plot, lag_plot',\n",
       " 'from pandas.plotting import lag_plot',\n",
       " 'from pandas.tseries.offsets import *',\n",
       " 'from scipy import stats',\n",
       " 'from scipy.io import wavfile',\n",
       " 'from scipy.linalg import lstsq',\n",
       " 'from scipy.signal import hilbert',\n",
       " 'from scipy.stats import skew, kurtosis',\n",
       " 'from scipy.stats import zscore',\n",
       " 'from sklearn import datasets',\n",
       " 'from sklearn import set_config',\n",
       " 'from sklearn.base import BaseEstimator, ClassifierMixin',\n",
       " 'from sklearn.base import BaseEstimator, TransformerMixin',\n",
       " 'from sklearn.base import RegressorMixin, clone',\n",
       " 'from sklearn.base import clone',\n",
       " 'from sklearn.cluster import KMeans',\n",
       " 'from sklearn.compose import ColumnTransformer',\n",
       " 'from sklearn.compose import TransformedTargetRegressor',\n",
       " 'from sklearn.datasets import fetch_openml',\n",
       " 'from sklearn.datasets import load_boston',\n",
       " 'from sklearn.datasets import load_files',\n",
       " 'from sklearn.datasets import make_blobs',\n",
       " 'from sklearn.datasets import make_circles',\n",
       " 'from sklearn.datasets import make_classification',\n",
       " 'from sklearn.decomposition import PCA',\n",
       " 'from sklearn.dummy import DummyClassifier',\n",
       " 'from sklearn.dummy import DummyRegressor',\n",
       " 'from sklearn.ensemble import IsolationForest',\n",
       " 'from sklearn.ensemble import RandomForestClassifier',\n",
       " 'from sklearn.ensemble import RandomForestRegressor',\n",
       " 'from sklearn.feature_extraction.text import CountVectorizer',\n",
       " 'from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'from sklearn.feature_selection import SelectKBest, chi2',\n",
       " 'from sklearn.impute import SimpleImputer',\n",
       " 'from sklearn.linear_model import HuberRegressor',\n",
       " 'from sklearn.linear_model import Lasso',\n",
       " 'from sklearn.linear_model import LinearRegression',\n",
       " 'from sklearn.linear_model import LogisticRegression',\n",
       " 'from sklearn.linear_model import LogisticRegressionCV',\n",
       " 'from sklearn.linear_model import Ridge',\n",
       " 'from sklearn.linear_model import SGDRegressor',\n",
       " 'from sklearn.metrics import ConfusionMatrixDisplay',\n",
       " 'from sklearn.metrics import classification_report',\n",
       " 'from sklearn.metrics import confusion_matrix',\n",
       " 'from sklearn.metrics import f1_score',\n",
       " 'from sklearn.metrics import mean_absolute_error as MAE',\n",
       " 'from sklearn.metrics import mean_squared_error',\n",
       " 'from sklearn.metrics import mean_squared_error as MSE',\n",
       " 'from sklearn.metrics import mean_squared_error as mse',\n",
       " 'from sklearn.metrics import precision_score',\n",
       " 'from sklearn.metrics import r2_score',\n",
       " 'from sklearn.metrics import recall_score',\n",
       " 'from sklearn.metrics import roc_auc_score',\n",
       " 'from sklearn.metrics import roc_curve',\n",
       " 'from sklearn.model_selection import GridSearchCV',\n",
       " 'from sklearn.model_selection import KFold',\n",
       " 'from sklearn.model_selection import ParameterGrid',\n",
       " 'from sklearn.model_selection import ShuffleSplit',\n",
       " 'from sklearn.model_selection import TimeSeriesSplit',\n",
       " 'from sklearn.model_selection import cross_validate',\n",
       " 'from sklearn.model_selection import train_test_split',\n",
       " 'from sklearn.neighbors import KNeighborsClassifier',\n",
       " 'from sklearn.neighbors import NearestNeighbors',\n",
       " 'from sklearn.neural_network import MLPClassifier',\n",
       " 'from sklearn.pipeline import Pipeline',\n",
       " 'from sklearn.pipeline import make_pipeline',\n",
       " 'from sklearn.preprocessing import FunctionTransformer',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from sklearn.preprocessing import MinMaxScaler',\n",
       " 'from sklearn.preprocessing import OneHotEncoder',\n",
       " 'from sklearn.preprocessing import OrdinalEncoder',\n",
       " 'from sklearn.preprocessing import PolynomialFeatures',\n",
       " 'from sklearn.preprocessing import PowerTransformer',\n",
       " 'from sklearn.preprocessing import QuantileTransformer',\n",
       " 'from sklearn.preprocessing import RobustScaler',\n",
       " 'from sklearn.preprocessing import StandardScaler',\n",
       " 'from sklearn.preprocessing import StandardScaler, FunctionTransformer',\n",
       " 'from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler',\n",
       " 'from sklearn.preprocessing import scale',\n",
       " 'from sklearn.svm import LinearSVC',\n",
       " 'from sklearn.svm import SVC',\n",
       " 'from sklearn.tree import DecisionTreeClassifier',\n",
       " 'from sklearn.tree import plot_tree',\n",
       " 'from statsmodels.tsa.deterministic import DeterministicProcess',\n",
       " 'from statsmodels.tsa.seasonal import STL',\n",
       " 'from statsmodels.tsa.stattools import adfuller',\n",
       " 'from statsmodels.tsa.stattools import kpss',\n",
       " 'from tensorflow import keras',\n",
       " 'from tensorflow.keras import Sequential',\n",
       " 'from tensorflow.keras import activations',\n",
       " 'from tensorflow.keras import backend as K',\n",
       " 'from tensorflow.keras import initializers',\n",
       " 'from tensorflow.keras import losses',\n",
       " 'from tensorflow.keras import metrics',\n",
       " 'from tensorflow.keras import optimizers',\n",
       " 'from tensorflow.keras.applications.xception import decode_predictions',\n",
       " 'from tensorflow.keras.datasets.mnist import load_data',\n",
       " 'from tensorflow.keras.layers import (Conv2D, BatchNormalization, Dropout,',\n",
       " 'from tensorflow.keras.layers import Dense',\n",
       " 'from tensorflow.keras.preprocessing.image import ImageDataGenerator',\n",
       " 'from zipfile import ZipFile',\n",
       " 'import IPython.display as ipd',\n",
       " 'import PIL.Image as Image',\n",
       " 'import json',\n",
       " 'import librosa',\n",
       " 'import librosa.display',\n",
       " 'import matplotlib.patheffects as path_effects',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import matplotlib.pyplot as plt_exts',\n",
       " 'import missingno as msno',\n",
       " 'import nltk',\n",
       " 'import noisereduce as nr',\n",
       " 'import numpy',\n",
       " 'import numpy as np',\n",
       " 'import numpy.polynomial.polynomial as poly',\n",
       " 'import os',\n",
       " 'import os, sys',\n",
       " 'import pandas as pd',\n",
       " 'import pickle',\n",
       " 'import random',\n",
       " 'import re',\n",
       " 'import requests',\n",
       " 'import scipy',\n",
       " 'import scipy.stats as stats',\n",
       " 'import seaborn',\n",
       " 'import seaborn as sns',\n",
       " 'import sqlite3',\n",
       " 'import statsmodels.api as sm',\n",
       " 'import string',\n",
       " 'import tensorflow as tf',\n",
       " 'import tensorflow.keras as keras',\n",
       " 'import tensorflow_hub as hub',\n",
       " 'import tensorflow_text',\n",
       " 'import w, sys',\n",
       " 'import warnings'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all import statements\n",
    "all_import_statements = []\n",
    "for notebook_file in notebook_files:\n",
    "    file_content = repo.get_contents(notebook_file).decoded_content.decode(\"utf-8\")\n",
    "    notebook_content = json.loads(file_content)\n",
    "    all_import_statements.extend(extract_import_statements(notebook_content))\n",
    "\n",
    "set(all_import_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(len(set(all_import_statements)))\n",
    "\n",
    "# Remove specific import statements\n",
    "all_import_statements = [\n",
    "    stmt\n",
    "    for stmt in all_import_statements\n",
    "    if stmt != \"from components import QuizzComponent\" and stmt != \"import w, sys\"\n",
    "]\n",
    "\n",
    "# Display the updated list\n",
    "len(set(all_import_statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a set to get unique import statements\n",
    "unique_import_statements = set(all_import_statements)\n",
    "\n",
    "# Save the unique import statements to a file\n",
    "with open(\"unique_import_statements.txt\", \"w\") as file:\n",
    "    for statement in unique_import_statements:\n",
    "        file.write(statement + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Activate the environment and check whether the import statements are fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load unique_import_statements.txt file\n",
    "with open(\"unique_import_statements.txt\", \"r\") as file:\n",
    "    unique_import_statements = file.readlines()\n",
    "\n",
    "len(unique_import_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khalilza/miniconda3/envs/adsml/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported: from sklearn.preprocessing import PolynomialFeatures\n",
      "\n",
      "Successfully imported: from nltk.corpus import stopwords\n",
      "\n",
      "Successfully imported: from scipy.linalg import lstsq\n",
      "\n",
      "Successfully imported: from sklearn.metrics import r2_score\n",
      "\n",
      "Successfully imported: import random\n",
      "\n",
      "Successfully imported: import pickle\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import scale\n",
      "\n",
      "Successfully imported: from sklearn.metrics import confusion_matrix\n",
      "\n",
      "Successfully imported: from sklearn.metrics import roc_curve\n",
      "\n",
      "Successfully imported: import tensorflow as tf\n",
      "\n",
      "Failed to import: import noisereduce as nr\n",
      " - Error: No module named 'torch'\n",
      "Successfully imported: from tensorflow import keras\n",
      "\n",
      "Successfully imported: import IPython.display as ipd\n",
      "\n",
      "Successfully imported: from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "Successfully imported: import os\n",
      "\n",
      "Successfully imported: import numpy as np\n",
      "\n",
      "Successfully imported: from sklearn.ensemble import RandomForestRegressor\n",
      "\n",
      "Successfully imported: from tensorflow.keras import initializers\n",
      "\n",
      "Successfully imported: from sklearn.compose import TransformedTargetRegressor\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import PowerTransformer\n",
      "\n",
      "Successfully imported: from scipy.io import wavfile\n",
      "\n",
      "Successfully imported: import re\n",
      "\n",
      "Successfully imported: from sklearn.metrics import mean_squared_error\n",
      "\n",
      "Successfully imported: from statsmodels.tsa.stattools import adfuller\n",
      "\n",
      "Successfully imported: from pandas.plotting import autocorrelation_plot, lag_plot\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import ShuffleSplit\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import KFold\n",
      "\n",
      "Successfully imported: from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "Successfully imported: import PIL.Image as Image\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import Lasso\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "Successfully imported: import matplotlib.pyplot as plt\n",
      "\n",
      "Successfully imported: from tensorflow.keras.datasets.mnist import load_data\n",
      "\n",
      "Successfully imported: from sklearn.impute import SimpleImputer\n",
      "\n",
      "Successfully imported: from sklearn.metrics import classification_report\n",
      "\n",
      "Successfully imported: from sklearn.datasets import load_files\n",
      "\n",
      "Successfully imported: from sklearn.svm import LinearSVC\n",
      "\n",
      "Successfully imported: from pandas.tseries.offsets import *\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import HuberRegressor\n",
      "\n",
      "Successfully imported: from itertools import product\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import train_test_split\n",
      "\n",
      "Successfully imported: from sklearn.datasets import fetch_openml\n",
      "\n",
      "Successfully imported: from sklearn.base import clone\n",
      "\n",
      "Successfully imported: import matplotlib.patheffects as path_effects\n",
      "\n",
      "Successfully imported: import requests\n",
      "\n",
      "Successfully imported: from scipy.stats import zscore\n",
      "\n",
      "Successfully imported: from bs4 import BeautifulSoup\n",
      "\n",
      "Successfully imported: import numpy.polynomial.polynomial as poly\n",
      "\n",
      "Successfully imported: from sklearn.tree import plot_tree\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import FunctionTransformer\n",
      "\n",
      "Successfully imported: from statsmodels.tsa.seasonal import STL\n",
      "\n",
      "Successfully imported: from collections import Counter\n",
      "\n",
      "Successfully imported: from PIL import Image\n",
      "\n",
      "Successfully imported: from sklearn.pipeline import make_pipeline\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import cross_validate\n",
      "\n",
      "Successfully imported: import missingno as msno\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import TimeSeriesSplit\n",
      "\n",
      "Successfully imported: import seaborn as sns\n",
      "\n",
      "Successfully imported: import matplotlib.pyplot as plt_exts\n",
      "\n",
      "Successfully imported: from pandas import json_normalize\n",
      "\n",
      "Successfully imported: import pandas as pd\n",
      "\n",
      "Successfully imported: from sklearn.decomposition import PCA\n",
      "\n",
      "Successfully imported: from sklearn.metrics import mean_absolute_error as MAE\n",
      "\n",
      "Successfully imported: from sklearn.base import RegressorMixin, clone\n",
      "\n",
      "Successfully imported: from tensorflow.keras.layers import Dense\n",
      "\n",
      "Successfully imported: from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "Successfully imported: import statsmodels.api as sm\n",
      "\n",
      "Successfully imported: from zipfile import ZipFile\n",
      "\n",
      "Successfully imported: import tensorflow_hub as hub\n",
      "\n",
      "Successfully imported: from tensorflow.keras import losses\n",
      "\n",
      "Successfully imported: from matplotlib.patches import Ellipse\n",
      "\n",
      "Successfully imported: from pandas.plotting import lag_plot\n",
      "\n",
      "Successfully imported: from nltk.tokenize import TreebankWordTokenizer\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "Successfully imported: from sklearn.metrics import ConfusionMatrixDisplay\n",
      "\n",
      "Successfully imported: from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "Successfully imported: from sklearn.dummy import DummyClassifier\n",
      "\n",
      "Successfully imported: import string\n",
      "\n",
      "Successfully imported: from scipy import stats\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
      "\n",
      "Successfully imported: from statsmodels.tsa.deterministic import DeterministicProcess\n",
      "\n",
      "Successfully imported: from nltk.stem.porter import PorterStemmer\n",
      "\n",
      "Successfully imported: from sklearn.datasets import make_classification\n",
      "\n",
      "Successfully imported: import librosa.display\n",
      "\n",
      "Successfully imported: from sklearn.compose import ColumnTransformer\n",
      "\n",
      "Failed to import: from tensorflow.keras.layers import (Conv2D, BatchNormalization, Dropout,\n",
      " - Error: unexpected EOF while parsing (<string>, line 1)\n",
      "Successfully imported: from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import OrdinalEncoder\n",
      "\n",
      "Successfully imported: import scipy\n",
      "\n",
      "Successfully imported: from sklearn.feature_selection import SelectKBest, chi2\n",
      "\n",
      "Successfully imported: from sklearn.cluster import KMeans\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import SGDRegressor\n",
      "\n",
      "Successfully imported: from sklearn.metrics import f1_score\n",
      "\n",
      "Successfully imported: from sklearn.dummy import DummyRegressor\n",
      "\n",
      "Successfully imported: from sklearn.datasets import make_circles\n",
      "\n",
      "Successfully imported: from sklearn.ensemble import IsolationForest\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import Ridge\n",
      "\n",
      "Successfully imported: import tensorflow.keras as keras\n",
      "\n",
      "Successfully imported: import sqlite3\n",
      "\n",
      "Successfully imported: from gensim.models import Phrases\n",
      "\n",
      "Successfully imported: from sklearn.metrics import roc_auc_score\n",
      "\n",
      "Successfully imported: from sklearn.metrics import mean_squared_error as mse\n",
      "\n",
      "Successfully imported: from nltk.tokenize import sent_tokenize\n",
      "\n",
      "Successfully imported: from sklearn.datasets import load_boston\n",
      "\n",
      "Failed to import: import tensorflow_text\n",
      " - Error: No module named 'tensorflow_text'\n",
      "Successfully imported: import os, sys\n",
      "\n",
      "Successfully imported: from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "Successfully imported: from scipy.signal import hilbert\n",
      "\n",
      "Successfully imported: from sklearn.datasets import make_blobs\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
      "\n",
      "Successfully imported: from tensorflow.keras import Sequential\n",
      "\n",
      "Successfully imported: from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "Successfully imported: from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "Successfully imported: from tensorflow.keras import backend as K\n",
      "\n",
      "Successfully imported: from sklearn.base import BaseEstimator, ClassifierMixin\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "Successfully imported: from sklearn.metrics import recall_score\n",
      "\n",
      "Successfully imported: from scipy.stats import skew, kurtosis\n",
      "\n",
      "Successfully imported: from tensorflow.keras.applications.xception import decode_predictions\n",
      "\n",
      "Successfully imported: import warnings\n",
      "\n",
      "Successfully imported: import scipy.stats as stats\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import LinearRegression\n",
      "\n",
      "Successfully imported: import librosa\n",
      "\n",
      "Successfully imported: from sklearn import set_config\n",
      "\n",
      "Successfully imported: from sklearn.metrics import mean_squared_error as MSE\n",
      "\n",
      "Successfully imported: from sklearn.svm import SVC\n",
      "\n",
      "Successfully imported: from tensorflow.keras import optimizers\n",
      "\n",
      "Successfully imported: from matplotlib import pyplot as plt\n",
      "\n",
      "Successfully imported: from tensorflow.keras import metrics\n",
      "\n",
      "Successfully imported: from sklearn.linear_model import LogisticRegressionCV\n",
      "\n",
      "Successfully imported: from tensorflow.keras import activations\n",
      "\n",
      "Successfully imported: from sklearn.metrics import precision_score\n",
      "\n",
      "Successfully imported: from sklearn.neighbors import NearestNeighbors\n",
      "\n",
      "Successfully imported: from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "Successfully imported: from sklearn.neural_network import MLPClassifier\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import QuantileTransformer\n",
      "\n",
      "Successfully imported: from sklearn.model_selection import ParameterGrid\n",
      "\n",
      "Successfully imported: from sklearn.pipeline import Pipeline\n",
      "\n",
      "Successfully imported: from IPython.display import display\n",
      "\n",
      "Successfully imported: from sklearn import datasets\n",
      "\n",
      "Successfully imported: import nltk\n",
      "\n",
      "Successfully imported: from statsmodels.tsa.stattools import kpss\n",
      "\n",
      "Successfully imported: from sklearn.preprocessing import RobustScaler\n",
      "\n",
      "Successfully imported: import json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if import statements work\n",
    "def check_imports(import_statements):\n",
    "\tfor statement in import_statements:\n",
    "\t\ttry:\n",
    "\t\t\texec(statement)\n",
    "\t\t\tprint(f\"Successfully imported: {statement}\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Failed to import: {statement} - Error: {e}\")\n",
    "\n",
    "# check all collected import statements\n",
    "check_imports(set(unique_import_statements))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two failures:\n",
    "# Failed to import: import tensorflow_text\n",
    "#  - Error: No module named 'tensorflow_text'\n",
    "\n",
    "#  Failed to import: from tensorflow.keras.layers import (Conv2D, BatchNormalization, Dropout,\n",
    "#  - Error: unexpected EOF while parsing (<string>, line 1)\n",
    "\n",
    "# under the current env we have the following failure too:\n",
    "# Failed to import: import noisereduce as nr\n",
    "#  - Error: No module named 'torch'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
